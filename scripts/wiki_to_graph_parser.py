import re
import os
import pandas as pd
from bs4 import BeautifulSoup

# ==========================================
# 1. ê³ í•´ìƒë„ ê´€ê³„ ë§¤í•‘ ë¡œì§ (ìœ ì§€)
# ==========================================
def get_predicate(ontology_tag, text_value, context_hint=""):
    # [1] ì¸ë¬¼/ì¡°ì§
    if "Participant" in ontology_tag:
        if any(keyword in context_hint for keyword in ["ì„¤ê³„", "ê±´ì¶•ì‚¬", "ê°ë…"]): return "kmua:designedBy"
        elif any(keyword in context_hint for keyword in ["ì‹œê³µ", "ì²­ë¶€", "í˜•ë¬´ì†Œ", "ê³µì‚¬"]): return "kmua:constructedBy"
        elif any(keyword in context_hint for keyword in ["ì„¤ë¹„", "ì „ê¸°", "ë‚œë°©", "ìœ„ìƒ"]): return "kmua:equippedBy"
        return "cidoc:hasParticipant"

    # [2] ë§ˆê°ì¬
    if "Covering" in ontology_tag or "Finish" in ontology_tag:
        if any(w in context_hint for w in ["ë°”ë‹¥", "ê¹”ê¸°", "ë‹¤ë‹¤ë¯¸", "ë¦¬ë†€ë¥¨"]): return "kmua:hasFloorFinish"
        elif any(w in context_hint for w in ["ë²½", "ì§•ë‘ë¦¬", "ë²½ì§€"]): return "kmua:hasWallFinish"
        elif any(w in context_hint for w in ["ì²œì¥", "ë°˜ì£½"]): return "kmua:hasCeilingFinish"
        elif any(w in context_hint for w in ["ì™¸ë²½", "í™”ê°•ì„", "ì²˜ë§ˆ"]): return "kmua:hasExteriorFinish"
        return "kmua:hasFinishDetail"

    # [3] ì„¤ë¹„
    if "Heating" in ontology_tag: return "brick:feedsHeatTo"
    if "HVAC" in ontology_tag: return "brick:feedsAirTo"
    if "Plumbing" in ontology_tag: return "brick:providesWaterTo"
    if "Lighting" in ontology_tag: return "brick:hasLighting"
    if "Elevator" in ontology_tag: return "kmua:hasVerticalTransport"
    if "Communication" in ontology_tag: return "brick:hasPoint"

    # [4] ê³µê°„/ê¸°íƒ€
    if "Storey" in ontology_tag: return "bot:hasStorey"
    if "Space" in ontology_tag: return "bot:containsZone"
    if "isLocatedIn" in ontology_tag: return "kmua:isLocatedIn"
    if "hasCost" in ontology_tag or "hasTotalCost" in ontology_tag: return "kmua:hasTotalBudget"

    return "kmua:relatedTo"

# ==========================================
# 2. íŒŒì„œ (XML ë³¸ë¬¸ ì¶”ì¶œ í¬í•¨)
# ==========================================
def extract_text_from_xml(xml_content):
    try:
        soup = BeautifulSoup(xml_content, "html.parser")
        text_tag = soup.find("text")
        if text_tag:
            return text_tag.get_text()
        else:
            return xml_content
    except Exception as e:
        print(f"âš ï¸ XML íŒŒì‹± ê²½ê³ : {e}")
        return xml_content

def parse_wiki_text(doc_name, wiki_source):
    triples = []
    triples.append({"Subject": doc_name, "Predicate": "rdf:type", "Object": "ModernArchitecture", "Label": "Building"})

    lines = wiki_source.split('\n')
    current_context = "" 

    for line in lines:
        line_soup = BeautifulSoup(line, "html.parser")
        line_text = line_soup.get_text()
        current_context = line_text 
        
        spans = line_soup.find_all("span")
        for span in spans:
            if span.has_attr("title"):
                ontology_tag = span["title"]
                entity_value = span.get_text().strip()
                
                predicate = get_predicate(ontology_tag, entity_value, context_hint=current_context)
                
                label = "Entity"
                if "Participant" in ontology_tag: label = "Actor"
                elif "Storey" in ontology_tag or "Space" in ontology_tag: label = "Space"
                elif "brick" in ontology_tag: label = "Facility"
                elif "Material" in ontology_tag or "Covering" in ontology_tag: label = "Material"
                
                triples.append({
                    "Subject": doc_name,
                    "Predicate": predicate,
                    "Object": entity_value,
                    "Label": label
                })
    return triples

# ==========================================
# 3. ê²½ë¡œ ì„¤ì • (output_csv ì €ì¥ìš©)
# ==========================================

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ìœ„ì¹˜(scripts í´ë”)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œë¥¼ ì¡ìŠµë‹ˆë‹¤.
BASE_DIR = os.path.dirname(os.path.abspath(__file__)) 
SOURCE_DIR = os.path.abspath(os.path.join(BASE_DIR, '..', 'source_data'))
OUTPUT_DIR = os.path.abspath(os.path.join(BASE_DIR, '..', 'output_csv'))

# output_csv í´ë”ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„±
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

def run_conversion(filename, doc_name):
    # 1. íŒŒì¼ ì½ê¸°
    file_path = os.path.join(SOURCE_DIR, filename)
    
    if not os.path.exists(file_path):
        print(f"âŒ ì˜¤ë¥˜: source_data í´ë”ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤ -> {filename}")
        return

    with open(file_path, 'r', encoding='utf-8') as f:
        raw_content = f.read()

    # 2. XML ì²˜ë¦¬
    if filename.lower().endswith('.xml'):
        print(f"ğŸ“‚ XML íŒŒì¼ ì²˜ë¦¬ ì¤‘: {filename}")
        wiki_text = extract_text_from_xml(raw_content)
    else:
        wiki_text = raw_content
    
    # 3. íŒŒì‹± ë° ë°ì´í„°í”„ë ˆì„ ë³€í™˜
    triples = parse_wiki_text(doc_name, wiki_text)
    df = pd.DataFrame(triples)
    
    # 4. CSV ì €ì¥ (output_csv í´ë”ì—ë§Œ ì €ì¥)
    csv_name = f"kmua_{doc_name}.csv"
    output_path = os.path.join(OUTPUT_DIR, csv_name)
    
    df.to_csv(output_path, index=False, encoding='utf-8-sig')
    
    print(f"âœ… ë³€í™˜ ì™„ë£Œ!")
    print(f"   - ì €ì¥ ê²½ë¡œ: {output_path}")
    print(f"   - ë°ì´í„° ê°œìˆ˜: {len(df)}ê°œ")

# ==========================================
# â˜… ì‹¤í–‰
# ==========================================
if __name__ == "__main__":
    # ì„ ìƒë‹˜ í´ë”ì— ìˆëŠ” íŒŒì¼ëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©
    target_filename = "07_11_ê²½ì„±ì¬íŒì†Œ.xml"  
    
    run_conversion(target_filename, "Gyeongseong_Court")