# íŒŒì¼ëª…: src/01_text_mining/03_composition.py
import os
import pandas as pd
from janome.tokenizer import Tokenizer

# ==========================================
# 1. í”„ë¡œì íŠ¸ ê²½ë¡œ ìë™ ì„¤ì • (ìƒëŒ€ ê²½ë¡œ)
# ==========================================
# í˜„ì¬ íŒŒì¼ ìœ„ì¹˜: kmua.../src/01_text_mining/
BASE_DIR = os.path.dirname(os.path.abspath(__file__)) 
# í”„ë¡œì íŠ¸ ë£¨íŠ¸: kmua.../
ROOT_DIR = os.path.dirname(os.path.dirname(BASE_DIR)) 

# [ì…ë ¥ 1] ì›ë³¸ í…ìŠ¤íŠ¸ íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë”
DATA_DIR = os.path.join(ROOT_DIR, 'data', '01_raw_txt')

# [ì…ë ¥ 2] í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ì—‘ì…€ íŒŒì¼ (Step 1 ê²°ê³¼ë¬¼)
# â€» íŒŒì¼ëª…ì´ 'q1_refined_result.xlsx'ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤. ë‹¤ë¥´ë©´ ìˆ˜ì •í•˜ì„¸ìš”.
CLUSTER_FILE = os.path.join(ROOT_DIR, 'data', '02_mining_results', 'q1_refined_result.xlsx')

# [ì¶œë ¥] ì¡°ì„±ë¹„ ê³„ì‚° ê²°ê³¼ ì €ì¥ ê²½ë¡œ
OUTPUT_FILE = os.path.join(ROOT_DIR, 'data', '02_mining_results', 'document_composition_scores.xlsx')

# ==========================================
# 2. ì‹¤í–‰ ë¡œì§ (q3_document_scoring.py ë‚´ìš©)
# ==========================================
def run_composition_scoring():
    # (1) í´ëŸ¬ìŠ¤í„° ë°ì´í„° ë¡œë“œ
    if not os.path.exists(CLUSTER_FILE):
        print(f"âŒ Error: í´ëŸ¬ìŠ¤í„° ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤ -> {CLUSTER_FILE}")
        return

    print("ğŸš€ ë¬¸ì„œ ì¡°ì„±ë¹„ ìŠ¤ì½”ì–´ë§ ì‹œì‘...")
    df_clusters = pd.read_excel(CLUSTER_FILE)
    
    # ë‹¨ì–´-ë¼ë²¨ ë§¤í•‘ ì‚¬ì „ ìƒì„± (Word -> Cluster ID)
    # ì—‘ì…€ì— 'Word'ì™€ 'Cluster' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    word_label_map = dict(zip(df_clusters['Word'], df_clusters['Cluster']))
    unique_labels = sorted(df_clusters['Cluster'].unique())

    # (2) í…ìŠ¤íŠ¸ íŒŒì¼ ìˆœíšŒ ë° ì ìˆ˜ ê³„ì‚°
    t = Tokenizer()
    doc_scores = []
    
    # ë°ì´í„° í´ë”ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ ì²˜ë¦¬
    if not os.path.exists(DATA_DIR):
        print(f"Error: ë°ì´í„° í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤ -> {DATA_DIR}")
        return

    file_list = [f for f in os.listdir(DATA_DIR) if f.endswith('.txt')]
    print(f"ğŸ“„ ì´ {len(file_list)}ê°œì˜ ë¬¸ì„œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

    for idx, filename in enumerate(file_list):
        if idx % 50 == 0: print(f"   - ì§„í–‰ë¥ : {idx}/{len(file_list)}")
        
        file_path = os.path.join(DATA_DIR, filename)
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                text = f.read()
        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ({filename}): {e}")
            continue
        
        if not text: continue

        # ëª…ì‚¬ ì¶”ì¶œ (Janome)
        tokens = t.tokenize(text)
        words = [token.surface for token in tokens if token.part_of_speech.startswith('åè©')]
        
        # ì¹´ìš´íŒ… ì´ˆê¸°í™”
        counts = {label: 0 for label in unique_labels}
        total_valid_words = 0
        
        # ë§¤í•‘ëœ ë‹¨ì–´ ì¹´ìš´íŠ¸
        for word in words:
            if word in word_label_map:
                label = word_label_map[word]
                counts[label] += 1
                total_valid_words += 1
        
        # ë¹„ìœ¨ ê³„ì‚° (%)
        if total_valid_words > 0:
            scores = {f"Label_{k}(%)": round((v / total_valid_words) * 100, 1) for k, v in counts.items()}
        else:
            scores = {f"Label_{k}(%)": 0 for k in unique_labels}
            
        scores['FileName'] = filename
        scores['Total_Keywords'] = total_valid_words
        doc_scores.append(scores)

    # (3) ê²°ê³¼ ì €ì¥
    if not doc_scores:
        print("âš ï¸ ë¶„ì„ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_scores = pd.DataFrame(doc_scores)
    
    # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬: FileNameê³¼ Total_Keywordsë¥¼ ë§¨ ì•ìœ¼ë¡œ
    cols = ['FileName', 'Total_Keywords'] + [c for c in df_scores.columns if c not in ['FileName', 'Total_Keywords']]
    df_scores = df_scores[cols]
    
    # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    
    df_scores.to_excel(OUTPUT_FILE, index=False)
    print(f"ë¶„ì„ ì™„ë£Œ ê²°ê³¼ ì €ì¥ë¨: {OUTPUT_FILE}")

if __name__ == "__main__":
    run_composition_scoring()