# íŒŒì¼ëª…: src/02_graph_construction/wiki_parser.py
import os
import pandas as pd
import html  # <--- [ì¶”ê°€] ì´ ì¹œêµ¬ê°€ &lt; ë¥¼ < ë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤.
from bs4 import BeautifulSoup

# ==========================================
# 1. ê²½ë¡œ ì„¤ì • (ìë™í™”)
# ==========================================
# í˜„ì¬ íŒŒì¼ ìœ„ì¹˜: kmua.../src/02_graph_construction/
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(os.path.dirname(BASE_DIR))

# ì…ë ¥: ìœ„í‚¤ XML íŒŒì¼ë“¤ì´ ëª¨ì—¬ìˆëŠ” í´ë”
SOURCE_DIR = os.path.join(ROOT_DIR, 'data', '03_raw_xml')
# ì¶œë ¥: ë³€í™˜ëœ CSVê°€ ì €ì¥ë  í´ë”
OUTPUT_DIR = os.path.join(ROOT_DIR, 'data', '04_graph_csv')

if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

# ==========================================
# 2. ê³ í•´ìƒë„ ê´€ê³„ ë§¤í•‘ (Ontology Logic)
# ==========================================
def get_predicate(ontology_tag, text_value, context_hint=""):
    """
    íƒœê·¸ì™€ ë¬¸ë§¥ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ê´€ê³„ëª…(Predicate)ì„ ë„ì¶œ
    """
    # [1] ì¸ë¬¼/ì¡°ì§ (Role Inference)
    if "Participant" in ontology_tag:
        if any(k in context_hint for k in ["ì„¤ê³„", "ê±´ì¶•ì‚¬", "ê¸°ì‚¬"]): return "kmua:designedBy"
        elif any(k in context_hint for k in ["ì‹œê³µ", "ì²­ë¶€", "ê³µì‚¬", "ì¡°"]): return "kmua:constructedBy"
        elif any(k in context_hint for k in ["ì„¤ë¹„", "ì „ê¸°", "ë‚œë°©", "ìœ„ìƒ"]): return "kmua:equippedBy"
        return "cidoc:hasParticipant"

    # [2] ë§ˆê°ì¬ (Finish Detail)
    if "Covering" in ontology_tag or "Finish" in ontology_tag:
        if any(w in context_hint for w in ["ë°”ë‹¥", "ê¹”ê¸°", "ë‹¤ë‹¤ë¯¸", "ë§ˆë£¨"]): return "kmua:hasFloorFinish"
        elif any(w in context_hint for w in ["ë²½", "ì§•ë‘ë¦¬", "ë²½ì§€", "íƒ€ì¼"]): return "kmua:hasWallFinish"
        elif any(w in context_hint for w in ["ì²œì¥", "ë°˜ì£½", "ëª°íƒˆ"]): return "kmua:hasCeilingFinish"
        elif any(w in context_hint for w in ["ì™¸ë²½", "í™”ê°•ì„", "ë²½ëŒ"]): return "kmua:hasExteriorFinish"
        return "kmua:hasFinishDetail"

    # [3] ì„¤ë¹„ ì‹œìŠ¤í…œ (Technical System)
    if "Heating" in ontology_tag: return "brick:feedsHeatTo"
    if "Plumbing" in ontology_tag: return "brick:providesWaterTo"
    if "Lighting" in ontology_tag: return "brick:hasLighting"
    if "Elevator" in ontology_tag: return "kmua:hasVerticalTransport"

    # [4] ìˆ˜ì¹˜/ë‹¨ìœ„ ì •ë°€ ë§¤í•‘ (Unit Inference)
    # ì˜ˆì‚°/ë¹„ìš©
    if "hasCost" in ontology_tag or any(c in text_value for c in ["ì›", "ì—”"]):
        return "kmua:hasTotalBudget"
    # ë©´ì 
    if any(unit in text_value for unit in ["í‰", "í™‰", "ì‘", "m2", "ã¡"]):
        if "ëŒ€ì§€" in context_hint or "ë¶€ì§€" in context_hint: return "kmua:hasSiteArea"
        return "kmua:hasTotalArea"
    # ë†’ì´
    if any(unit in text_value for unit in ["ì²™", "ì´Œ", "ë¯¸í„°", "m"]):
        return "kmua:hasHeight"

    # [5] ê³µê°„ ë° ê¸°íƒ€
    if "Storey" in ontology_tag: return "bot:hasStorey"
    if "Space" in ontology_tag: return "bot:containsZone"
    if "isLocatedIn" in ontology_tag: return "kmua:isLocatedIn"

    return "kmua:relatedTo"

# ==========================================
# 3. íŒŒì‹± ì—”ì§„ (XML -> Triples)
# ==========================================
def extract_text_from_xml(xml_content):
    try:
        # 1. ì „ì²´ XML êµ¬ì¡°ë¥¼ ë¨¼ì € íŒŒì‹±
        soup = BeautifulSoup(xml_content, "html.parser")
        
        # 2. <text> íƒœê·¸ ì°¾ê¸°
        text_tag = soup.find("text")
        
        if text_tag:
            # 3. [í•µì‹¬] &lt; ë“±ì„ < ë¡œ ë³€í™˜ (Unescape)
            # get_text()ë§Œ ì¨ë„ ì¼ë¶€ ë˜ì§€ë§Œ, html.unescapeë¡œ í™•ì‹¤í•˜ê²Œ ì²˜ë¦¬
            raw_text = text_tag.get_text()
            clean_text = html.unescape(raw_text)
            return clean_text
        else:
            return xml_content
    except:
        return xml_content

# ==========================================
# 4. ì‹¤í–‰ (Batch Process)
# ==========================================
def run_batch_conversion():
    if not os.path.exists(SOURCE_DIR):
        print(f"âŒ Error: ì…ë ¥ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤ -> {SOURCE_DIR}")
        return

    xml_files = [f for f in os.listdir(SOURCE_DIR) if f.endswith('.xml')]
    
    if not xml_files:
        print(f"âš ï¸ ê²½ê³ : {SOURCE_DIR} í´ë”ì— XML íŒŒì¼ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤!")
        return

    print(f"ğŸš€ ì´ {len(xml_files)}ê°œì˜ XML íŒŒì¼ì„ ë³€í™˜í•©ë‹ˆë‹¤...")

    for filename in xml_files:
        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ì—¬ ë¬¸ì„œ IDë¡œ ì‚¬ìš© (ì˜ˆ: 07_11_ê²½ì„±ì¬íŒì†Œ)
        doc_name = os.path.splitext(filename)[0]
        # í•œê¸€ì´ë‚˜ íŠ¹ìˆ˜ë¬¸ìê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        safe_doc_name = doc_name.replace(" ", "_")

        file_path = os.path.join(SOURCE_DIR, filename)
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = extract_text_from_xml(f.read())
            
            triples = parse_wiki_text(safe_doc_name, content)
            df = pd.DataFrame(triples)
            
            # ê²°ê³¼ ì €ì¥
            output_csv = f"kmua_{safe_doc_name}.csv"
            output_path = os.path.join(OUTPUT_DIR, output_csv)
            df.to_csv(output_path, index=False, encoding='utf-8-sig')
            
            print(f"  âœ… ë³€í™˜ ì™„ë£Œ: {filename} -> {output_csv}")
            
        except Exception as e:
            print(f" ì‹¤íŒ¨ ({filename}): {e}")

    print("\n ã„´ëª¨ë“  ë³€í™˜ ì‘ì—…ì´ ëë‚¬ìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    run_batch_conversion()